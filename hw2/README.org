#+NAME: start up server
#+BEGIN_SRC bash
cd hw2
uvicorn app.main:app --reload
#+END_SRC


#+NAME: run tests
#+BEGIN_SRC bash
  cd hw2/app/tests
python3 -m pytest
#+END_SRC

#+NAME: how to train model for inference
#+BEGIN_SRC bash
  cd hw1
python3 pipeline_train.py
#+END_SRC
The take modes from hw1/models

* Usage
  
#+NAME: start up server
#+BEGIN_SRC bash
    cd hw2
  docker-compose up --build
#+END_SRC

Then enter the docker and use ~request.py~ utility to send request

* Docker image on Docker Hub
  docker: ~maxdrobin/inference~

  optimisation:
  - use python3 slim docker ~100m
  - install only nessacary libraries
  - add option ~--no-cache-dir~ to Dockerfile (decrease in size up to ~200m)
  - not copy data and models to docker, load them from volumes
  - combine run and copy commands in one where possible
  
