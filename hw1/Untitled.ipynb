{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn_pandas import DataFrameMapper, gen_features\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data\n",
    "We are not reading the original data from Kaggel.  \n",
    "The data we are reading is based on the data from Kaggle with small changes:\n",
    "* Random replacement of values with NaNs\n",
    "* Transformations of categorical (int) features to text categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/raw/heart.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls data/raw/heart.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=42)\n",
    "df_data = pd.read_csv(\"data/raw/heart.csv\")#, sep=';', index_col=\"id\")\n",
    "# display(df_data.describe())#include=\"all\"))\n",
    "# display(df_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declerations of all column types and target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_features = [[\"cp\"], ['restecg'], ['exang'], ['thal'], ['ca'], ['slope']]\n",
    "binary_features = [[\"sex\"], [\"fbs\"]]\n",
    "numeric_features = [[\"age\"], [\"trestbps\"], [\"chol\"], [\"thalach\"], [\"oldpeak\"]]\n",
    "target = \"target\"\n",
    "\n",
    "categorical_suffix = \"_#CAT#\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_data.copy()\n",
    "y = X.pop(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data to train test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create custom transformers for feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blood Pressure Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom transformer responsible for the creation of a new blood pressure categorical feature based on systolic (the number at the top) and diastolic (the number at the bottom) values.  \n",
    "The transformer will create a new categorical feature with values according to the American Heart Association ranges of blood pressure:\n",
    "* normal  \n",
    "* elevated  \n",
    "* high_pressure_stage_1  \n",
    "* high_pressure_stage_2  \n",
    "* hypertensive_crisis  \n",
    "  \n",
    "  \n",
    "![title](https://www.inquirer.com/resizer/jACzP-uAGFwY4JBAfo7tY6qUj-k=/1400x932/smart/arc-anglerfish-arc2-prod-pmn.s3.amazonaws.com/public/PHXNJPTEGRB4RCDYCFJZ6IBOZY.jpg)  \n",
    "Photo from [American Heart Association](https://www.heart.org/-/media/data-import/downloadables/pe-abh-what-is-high-blood-pressure-ucm_300310.pdf?la=en&hash=CAC0F1D377BDB7BC3870993918226869524AAC3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BloodPressureTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        # Systolic and diastolic blood pressure ranges based on the American Heart Association\n",
    "        self.systolic_ranges = [-np.inf, 119, 129, 139, 180, np.inf]\n",
    "        self.diastolic_ranges = [-np.inf, 79, 89, 120, np.inf]\n",
    "        \n",
    "        # Blood pressure categories\n",
    "        self.blood_pressure_category = [\"normal\", \"elevated\", \"high_pressure_stage_1\", \"high_pressure_stage_2\", \"hypertensive_crisis\"]\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Copy the data so we will not change the original instance\n",
    "        df_blood_pressure = X.copy()\n",
    "        \n",
    "        # Break down ranges of systolic values to categories\n",
    "        df_blood_pressure[\"systolic\"] = pd.cut(df_blood_pressure[\"ap_hi\"], self.systolic_ranges, labels=[\"<120\", \"120-129\", \"130-139\", \"140-180\", \">180\"])\n",
    "        \n",
    "        # Break down ranges of diastolic values to categories\n",
    "        df_blood_pressure[\"diastolic\"] = pd.cut(df_blood_pressure[\"ap_lo\"], self.diastolic_ranges, labels=[\"<79\", \"80-89\", \"90-120\", \">120\"])\n",
    "        \n",
    "        # Combine ranges from systolic and diastolic features to determine the category of the blood pressure feature\n",
    "        df_blood_pressure.loc[(df_blood_pressure[\"systolic\"] == \"<120\") &\n",
    "                              (df_blood_pressure[\"diastolic\"] == \"<79\"), \"blood_pressure\"] = self.blood_pressure_category[0]\n",
    "        \n",
    "        df_blood_pressure.loc[(df_blood_pressure[\"systolic\"] == \"120-129\") &\n",
    "                              (df_blood_pressure[\"diastolic\"] == \"<79\"), \"blood_pressure\"] = self.blood_pressure_category[1]\n",
    "        \n",
    "        df_blood_pressure.loc[(df_blood_pressure[\"systolic\"] == \"130-139\") |\n",
    "                              (df_blood_pressure[\"diastolic\"] == \"80-89\"), \"blood_pressure\"] = self.blood_pressure_category[2]\n",
    "        \n",
    "        df_blood_pressure.loc[(df_blood_pressure[\"systolic\"] == \"140-180\") |\n",
    "                              (df_blood_pressure[\"diastolic\"] == \"90-120\"), \"blood_pressure\"] = self.blood_pressure_category[3]\n",
    "        \n",
    "        df_blood_pressure.loc[(df_blood_pressure[\"systolic\"] == \">180\") |\n",
    "                              (df_blood_pressure[\"diastolic\"] == \">120\"), \"blood_pressure\"] = self.blood_pressure_category[4]\n",
    "        \n",
    "        # Return blood pressure feature as a dataframe with one column\n",
    "        return df_blood_pressure[[\"blood_pressure\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unhealty Lifestyle Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom transformer responsible for the creation of a new \"unhealty lifestyle\" feature.  \n",
    "This is a boolean feature representing the use of cigarettes, alcohol, and physical inactivity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnhealtyLifestyleTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Copy the data so we will not change the original instance\n",
    "        df_unhealty_lifestyle = X.copy()\n",
    "        \n",
    "        # If you smoke or use alcohol or don't do physical activity, you maintain an unhealty lifestyle!\n",
    "        df_unhealty_lifestyle[\"unhealty_lifestyle\"] = df_unhealty_lifestyle[\"smoke\"] | df_unhealty_lifestyle[\"alco\"] | (1 - df_unhealty_lifestyle[\"active\"])\n",
    "        \n",
    "        # Return unhealty lifestyle feature as a dataframe with one column\n",
    "        return df_unhealty_lifestyle[[\"unhealty_lifestyle\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of DataFrameMapper transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define the pipeline of transformations and the raw features we need to complete the creation and processing of the new features and the original features.  \n",
    "We will pass this to the DataFrameMapper class of the sklearn-pandas package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ap_hi', 'ap_lo'],\n",
       " [BloodPressureTransformer(),\n",
       "  SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "         strategy='most_frequent', verbose=0)],\n",
       " {'alias': 'blood_pressure_#CAT#'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input features \"ap_hi\", \"ap_lo\".\n",
    "# Steps:\n",
    "#    BloodPressureTransformer - create blood pressure feature based on \"ap_hi\", \"ap_lo\".\n",
    "#    SimpleImputer - fill nans with the most frequent value.\n",
    "#    OneHotEncoder - encode categorical values as a one-hot numeric array.\n",
    "gen_blood_pressure = (\n",
    "    [\"ap_hi\", \"ap_lo\"],\n",
    "    [\n",
    "        BloodPressureTransformer(),\n",
    "        SimpleImputer(strategy=\"most_frequent\")\n",
    "    ],\n",
    "    {\"alias\": f\"blood_pressure{categorical_suffix}\"}\n",
    ")\n",
    "\n",
    "gen_blood_pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['smoke', 'alco', 'active'],\n",
       " [UnhealtyLifestyleTransformer(),\n",
       "  SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "         strategy='most_frequent', verbose=0)],\n",
       " {'alias': 'unhealty_lifestyle_#CAT#'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input features [\"smoke\", \"alco\", \"active\"].\n",
    "# Steps:\n",
    "#    UnhealtyLifestyleTransformer - create unhealty lifestyle feature based on \"smoke\", \"alco\", \"active\".\n",
    "#    SimpleImputer - fill nans with the most frequent value.\n",
    "gen_unhealty_lifestyle = (\n",
    "    [\"smoke\", \"alco\", \"active\"],\n",
    "    [\n",
    "        UnhealtyLifestyleTransformer(),\n",
    "        SimpleImputer(strategy=\"most_frequent\")\n",
    "    ],\n",
    "    {\"alias\": f\"unhealty_lifestyle{categorical_suffix}\"}\n",
    ")\n",
    "\n",
    "gen_unhealty_lifestyle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the same transformers for multiple columns with gen_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['cholesterol'],\n",
       "  [SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "          strategy='most_frequent', verbose=0)],\n",
       "  {'alias': 'cholesterol_#CAT#'}),\n",
       " (['gluc'], [SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "          strategy='most_frequent', verbose=0)], {'alias': 'gluc_#CAT#'})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input features [[\"cholesterol\"], [\"gluc\"]] (The columns are now list of lists because we want to send 2-dimentional DataFrame to each of the transformers).\n",
    "# Steps:\n",
    "#    SimpleImputer - fill nans with the most frequent value.\n",
    "#    OneHotEncoder - encode categorical values as a one-hot numeric array.\n",
    "gen_category = gen_features(\n",
    "    columns=category_features,\n",
    "    classes=[\n",
    "        {\n",
    "            \"class\": SimpleImputer,\n",
    "            \"strategy\": \"most_frequent\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "gen_category = [(col_name, transformer, {\"alias\": col_name[0] + categorical_suffix}) for col_name, transformer in gen_category]\n",
    "gen_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['gender'], [SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "          strategy='most_frequent', verbose=0)], {'alias': 'gender_#CAT#'}),\n",
       " (['smoke'], [SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "          strategy='most_frequent', verbose=0)], {'alias': 'smoke_#CAT#'}),\n",
       " (['alco'], [SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "          strategy='most_frequent', verbose=0)], {'alias': 'alco_#CAT#'}),\n",
       " (['active'], [SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "          strategy='most_frequent', verbose=0)], {'alias': 'active_#CAT#'})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input features [[\"gender\"], [\"smoke\"], [\"alco\"], [\"active\"]] (The columns are now list of lists because we want to send 2-dimentional DataFrame to each of the transformers).\n",
    "# Steps:\n",
    "#    SimpleImputer - fill nans with the most frequent value.\n",
    "gen_binary = gen_features(\n",
    "    columns=binary_features,\n",
    "    classes=[\n",
    "        {\n",
    "            \"class\": SimpleImputer,\n",
    "            \"strategy\": \"most_frequent\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "gen_binary = [(col_name, transformer, {\"alias\": col_name[0] + categorical_suffix}) for col_name, transformer in gen_binary]\n",
    "gen_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.   2.   3. ]\n",
      " [ 4.   3.5  6. ]\n",
      " [10.   3.5  9. ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp_mean.fit([[7, 2, 3], [4, np.nan, 6], [10, 5, 9]])\n",
    "\n",
    "X = [[np.nan, 2, 3], [4, np.nan, 6], [10, np.nan, 9]]\n",
    "print(imp_mean.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['age'],\n",
       "  [SimpleImputer(copy=True, fill_value=None, missing_values=nan, strategy='mean',\n",
       "          verbose=0),\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)]),\n",
       " (['height'],\n",
       "  [SimpleImputer(copy=True, fill_value=None, missing_values=nan, strategy='mean',\n",
       "          verbose=0),\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)]),\n",
       " (['weight'],\n",
       "  [SimpleImputer(copy=True, fill_value=None, missing_values=nan, strategy='mean',\n",
       "          verbose=0),\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)]),\n",
       " (['ap_hi'],\n",
       "  [SimpleImputer(copy=True, fill_value=None, missing_values=nan, strategy='mean',\n",
       "          verbose=0),\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)]),\n",
       " (['ap_lo'],\n",
       "  [SimpleImputer(copy=True, fill_value=None, missing_values=nan, strategy='mean',\n",
       "          verbose=0),\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input features [[\"age\"], [\"height\"], [\"weight\"], [\"ap_hi\"], [\"ap_lo\"]] (The columns are now list of lists because we want to send 2-dimentional DataFrame to each of the transformers).\n",
    "# Steps:\n",
    "#    SimpleImputer - fill nans with the mean value.\n",
    "#    StandardScaler - standardize features by removing the mean and scaling to unit variance.\n",
    "gen_numeric = gen_features(\n",
    "    columns=numeric_features,\n",
    "    classes=[\n",
    "        {\n",
    "            \"class\": SimpleImputer,\n",
    "            \"strategy\": \"mean\"\n",
    "        },\n",
    "        {\n",
    "            \"class\": StandardScaler\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "gen_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrameMapper Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define the course of action of the DataFrameMapper and indicate that the input and output will be Pandas Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_mapper = DataFrameMapper(\n",
    "    [\n",
    "        gen_blood_pressure,\n",
    "        gen_unhealty_lifestyle,\n",
    "        *gen_category,\n",
    "        *gen_binary,\n",
    "        *gen_numeric,\n",
    "    ],\n",
    "    input_df=True,\n",
    "    df_out=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blood_pressure_#CAT#</th>\n",
       "      <th>unhealty_lifestyle_#CAT#</th>\n",
       "      <th>cholesterol_#CAT#</th>\n",
       "      <th>gluc_#CAT#</th>\n",
       "      <th>gender_#CAT#</th>\n",
       "      <th>smoke_#CAT#</th>\n",
       "      <th>alco_#CAT#</th>\n",
       "      <th>active_#CAT#</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98125</th>\n",
       "      <td>high_pressure_stage_2</td>\n",
       "      <td>0</td>\n",
       "      <td>well_above_normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>women</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.388175</td>\n",
       "      <td>-0.549199</td>\n",
       "      <td>1.024035e-15</td>\n",
       "      <td>-0.056261</td>\n",
       "      <td>-0.035475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28510</th>\n",
       "      <td>high_pressure_stage_1</td>\n",
       "      <td>1</td>\n",
       "      <td>well_above_normal</td>\n",
       "      <td>well_above_normal</td>\n",
       "      <td>men</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.308468</td>\n",
       "      <td>0.333478</td>\n",
       "      <td>-6.621198e-01</td>\n",
       "      <td>-0.056261</td>\n",
       "      <td>-0.085423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>high_pressure_stage_2</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>women</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.346527</td>\n",
       "      <td>-0.549199</td>\n",
       "      <td>-5.900598e-01</td>\n",
       "      <td>-0.056261</td>\n",
       "      <td>-0.035475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39560</th>\n",
       "      <td>high_pressure_stage_2</td>\n",
       "      <td>0</td>\n",
       "      <td>well_above_normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>women</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.291463</td>\n",
       "      <td>-0.170909</td>\n",
       "      <td>-1.382720e+00</td>\n",
       "      <td>-0.024632</td>\n",
       "      <td>-0.035475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32677</th>\n",
       "      <td>high_pressure_stage_2</td>\n",
       "      <td>0</td>\n",
       "      <td>well_above_normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>women</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.912495</td>\n",
       "      <td>-0.801392</td>\n",
       "      <td>7.790809e-01</td>\n",
       "      <td>0.133513</td>\n",
       "      <td>-0.085423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        blood_pressure_#CAT#  unhealty_lifestyle_#CAT#  cholesterol_#CAT#  \\\n",
       "id                                                                          \n",
       "98125  high_pressure_stage_2                         0  well_above_normal   \n",
       "28510  high_pressure_stage_1                         1  well_above_normal   \n",
       "15795  high_pressure_stage_2                         0             normal   \n",
       "39560  high_pressure_stage_2                         0  well_above_normal   \n",
       "32677  high_pressure_stage_2                         0  well_above_normal   \n",
       "\n",
       "              gluc_#CAT# gender_#CAT#  smoke_#CAT#  alco_#CAT#  active_#CAT#  \\\n",
       "id                                                                             \n",
       "98125             normal        women            0           0             1   \n",
       "28510  well_above_normal          men            0           0             0   \n",
       "15795             normal        women            0           0             1   \n",
       "39560             normal        women            0           0             1   \n",
       "32677             normal        women            0           0             1   \n",
       "\n",
       "            age    height        weight     ap_hi     ap_lo  \n",
       "id                                                           \n",
       "98125  0.388175 -0.549199  1.024035e-15 -0.056261 -0.035475  \n",
       "28510  1.308468  0.333478 -6.621198e-01 -0.056261 -0.085423  \n",
       "15795  1.346527 -0.549199 -5.900598e-01 -0.056261 -0.035475  \n",
       "39560  1.291463 -0.170909 -1.382720e+00 -0.024632 -0.035475  \n",
       "32677  0.912495 -0.801392  7.790809e-01  0.133513 -0.085423  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_mapper.fit_transform(X_train, y_train).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom CatBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to implement our own catboost classifier so we can track our categorical features at runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCatBoostClassifier(CatBoostClassifier):\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        print(X.filter(regex=f\"{categorical_suffix}$\").columns.to_list())\n",
    "\n",
    "        return super().fit(\n",
    "            X,\n",
    "            y=y,\n",
    "            cat_features=X.filter(regex=f\"{categorical_suffix}$\").columns,\n",
    "            **fit_params\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the feature selection step, we create out own custom feature selection so the input dataframe will stay a dataframe and not numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomFeatureSelection(SelectFromModel):\n",
    "\n",
    "    def transform(self, X):\n",
    "        \n",
    "        # Get indices of important features\n",
    "        important_features_indices = list(self.get_support(indices=True))\n",
    "\n",
    "        # Select important features\n",
    "        _X = X.iloc[:, important_features_indices].copy()\n",
    "\n",
    "        return _X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we piece together all prevoius definitions to define the full pipeline:\n",
    "* preprocessing\n",
    "* feature selection\n",
    "* estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess_mapper),\n",
    "    (\"feature_selection\", CustomFeatureSelection(CustomCatBoostClassifier(logging_level=\"Silent\"))),\n",
    "    (\"estimator\", CustomCatBoostClassifier(logging_level=\"Silent\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blood_pressure_#CAT#', 'unhealty_lifestyle_#CAT#', 'cholesterol_#CAT#', 'gluc_#CAT#', 'gender_#CAT#', 'smoke_#CAT#', 'alco_#CAT#', 'active_#CAT#']\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "preds = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I created a grid search object which includes the original pipeline.  \n",
    "When I then call fit, the transformations are applied to the data, before a cross-validated grid-search is performed over the parameter grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess_mapper),\n",
    "    (\"feature_selection\", CustomFeatureSelection(CustomCatBoostClassifier(logging_level=\"Silent\"))),\n",
    "    (\"estimator\", CustomCatBoostClassifier(logging_level=\"Silent\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"estimator__depth\": [4, 5, 6],\n",
    "    \"estimator__iterations\": [500, 1000],\n",
    "    \"estimator__learning_rate\": [0.001, 0.01, 0.1], \n",
    "    \"estimator__l2_leaf_reg\": [3, 5, 100],\n",
    "    \"estimator__border_count\": [10, 50, 200],\n",
    "    \"estimator__ctr_border_count\": [10, 50, 200],\n",
    "    \"estimator__thread_count\": [4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv_estimator = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1)\n",
    "gscv_estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(gscv_estimator.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = gscv_estimator.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
